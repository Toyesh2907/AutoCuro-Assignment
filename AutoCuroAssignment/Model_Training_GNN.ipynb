{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c7ec86-a75b-4d7f-a1e7-d1438992d6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import grid\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn import Linear, ReLU, Dropout, BatchNorm1d, CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30a1d99-2157-40f2-95a7-f66605f3448f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'C:/Users/Lenovo/AutoCuroAssignment/tic_tac_toe_records_minimax_Preprocessed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract inputs and targets\n",
    "input_graphs = data['Input Graph'].apply(lambda x: eval(x))  # Directly extract as list\n",
    "targets = data['decision'] - 1  # Subtract 1 to get target range 0-8\n",
    "\n",
    "# Create PyTorch Geometric Data objects\n",
    "data_list = []\n",
    "for i in range(len(input_graphs)):\n",
    "    # Create a fully connected graph edge_index for a 3x3 grid\n",
    "    num_nodes = 9\n",
    "    edge_index = torch.tensor(list(itertools.permutations(range(num_nodes), 2)), dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Flatten the 3x3 grid into a 9-element feature vector\n",
    "    x = torch.tensor([val for row in input_graphs[i] for val in row], dtype=torch.float).view(-1, 1)  # Convert to tensor\n",
    "    y = torch.tensor(targets[i], dtype=torch.long)\n",
    "    data_list.append(Data(x=x, edge_index=edge_index, y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccaf71c5-3879-4ece-9939-3dcb44e0f830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader\n",
    "batch_size = 64\n",
    "loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3264b09-d23f-4412-a337-66334e0fb7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ComplexGNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexGNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 32)\n",
    "        self.conv2 = GCNConv(32, 64)\n",
    "        self.conv3 = GCNConv(64, 128)\n",
    "        self.conv4 = GCNConv(128, 256)\n",
    "\n",
    "        self.batch_norm1 = BatchNorm1d(32)\n",
    "        self.batch_norm2 = BatchNorm1d(64)\n",
    "        self.batch_norm3 = BatchNorm1d(128)\n",
    "        self.batch_norm4 = BatchNorm1d(256)\n",
    "\n",
    "        self.fc1 = Linear(256, 512)\n",
    "        self.fc2 = Linear(512, 256)\n",
    "        self.fc3 = Linear(256, 9)  # 9 possible moves (0-8)\n",
    "        \n",
    "        self.relu = ReLU()\n",
    "        self.dropout = Dropout(p=0.2)  # Dropout rate as specified    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        batch = data.batch  # Get batch tensor\n",
    "\n",
    "        # Forward pass through GCN layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e238d117-fba2-42a0-95a4-c6574af2af93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "model = ComplexGNNModel()\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "#scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(data_list) * split_ratio)\n",
    "train_data = data_list[:split_index]\n",
    "val_data = data_list[split_index:]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243ad6a1-a0ae-48fd-b8e3-5f7b4f0f4656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Training Loss: 1.8157, Training Accuracy: 0.3286, Validation Loss: 1.8374, Validation Accuracy: 0.3119\n",
      "Epoch 2/200, Training Loss: 1.8146, Training Accuracy: 0.3290, Validation Loss: 1.8357, Validation Accuracy: 0.3119\n",
      "Epoch 3/200, Training Loss: 1.8137, Training Accuracy: 0.3287, Validation Loss: 1.8362, Validation Accuracy: 0.3119\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m---> 31\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[0;32m     32\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(out, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     33\u001b[0m         total_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mComplexGNNModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Global mean pooling\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m x \u001b[38;5;241m=\u001b[39m global_mean_pool(x, batch)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Fully connected layers\u001b[39;00m\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\pool\\glob.py:63\u001b[0m, in \u001b[0;36mglobal_mean_pool\u001b[1;34m(x, batch, size)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scatter(x, batch, dim\u001b[38;5;241m=\u001b[39mdim, dim_size\u001b[38;5;241m=\u001b[39msize, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch_geometric\\utils\\_scatter.py:83\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[0;32m     80\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     82\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[1;32m---> 83\u001b[0m     out \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(size)\u001b[38;5;241m.\u001b[39mscatter_add_(dim, index, src)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;241m/\u001b[39m broadcast(count, out, dim)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# in case the input does not require gradients:\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)  # Output shape should be [batch_size, 9]\n",
    "        loss = criterion(out, batch.y)  # Target shape should be [batch_size]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(out, dim=1)\n",
    "        correct_train += (predicted == batch.y).sum().item()\n",
    "        total_train += batch.y.size(0)\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            out = model(batch)\n",
    "            loss = criterion(out, batch.y)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(out, dim=1)\n",
    "            correct_val += (predicted == batch.y).sum().item()\n",
    "            total_val += batch.y.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e630c86-552a-4408-beda-51e806019c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 4, 4, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9019fc69-5599-4e7d-b794-53505e5114a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on the Entire Dataset: 0.3253\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'C:/Users/Lenovo/AutoCuroAssignment/complex_gnn_model.pth')\n",
    "\n",
    "# Evaluation on the entire dataset\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(data_list, batch_size=batch_size, shuffle=False):\n",
    "        out = model(batch)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(batch.y)\n",
    "\n",
    "# Convert lists to tensors\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_targets.cpu(), all_preds.cpu())\n",
    "print(f'Final Accuracy on the Entire Dataset: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dad68a-1753-42b3-bf18-3c769a6b2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test output\n",
    "data=[[2, 1, 0], [0, 0, 2], [0, 1, 1]]\n",
    "num_nodes = 9\n",
    "edge_index = torch.tensor(list(itertools.permutations(range(num_nodes), 2)), dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Flatten the 3x3 grid into a 9-element feature vector\n",
    "x = torch.tensor([val for row in data for val in row], dtype=torch.float).view(-1, 1)  # Convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b2ee75-134b-4c30-8d23-961776139237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ComplexGNNModel()\n",
    "model.load_state_dict(torch.load('C:/Users/Lenovo/AutoCuroAssignment/complex_gnn_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adad16d5-73e0-4bb5-82d3-a4b63b6f81ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted move: 4\n",
      "Model Output:tensor([[ 0.1044, -0.3484,  0.2249, -0.2405,  0.4315, -0.2683,  0.1721, -0.3870,\n",
      "          0.1929]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the adjacency list for a 3x3 grid\n",
    "edges = [\n",
    "    (0, 1), (1, 0), (1, 2), (2, 1),  # Top row\n",
    "    (0, 3), (3, 0), (1, 4), (4, 1), (2, 5), (5, 2),  # Top row connected to middle row\n",
    "    (3, 4), (4, 3), (4, 5), (5, 4),  # Middle row\n",
    "    (3, 6), (6, 3), (4, 7), (7, 4), (5, 8), (8, 5),  # Middle row connected to bottom row\n",
    "    (6, 7), (7, 6), (7, 8), (8, 7)  # Bottom row\n",
    "]\n",
    "\n",
    "# Convert edge list to torch tensor\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Your input matrix\n",
    "input_matrix = [[1,1, 2], [2, 2, 1], [1,1, 0]]\n",
    "input_tensor = torch.tensor(input_matrix, dtype=torch.float).view(-1, 1)  # Flatten to [9, 1]\n",
    "\n",
    "# Create a Data object\n",
    "data = Data(x=input_tensor, edge_index=edge_index)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "\n",
    "# Interpret the output\n",
    "predicted_move = torch.argmax(output, dim=1).item()\n",
    "\n",
    "print(f'Predicted move: {predicted_move}')\n",
    "print(f'Model Output:{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6f9f7-1aef-4a99-9a55-94c4caacefba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
